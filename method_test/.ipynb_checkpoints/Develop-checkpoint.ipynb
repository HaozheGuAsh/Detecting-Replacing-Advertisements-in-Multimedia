{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-32-a8458a543dbd>, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-a8458a543dbd>\"\u001b[1;36m, line \u001b[1;32m45\u001b[0m\n\u001b[1;33m    def cut_copy_image(self, img, size, corner=[0,0]):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "class DetectIcon:\n",
    "    \n",
    "    def __init__(self, videoPath, iconPathSet):\n",
    "        self.width = 480\n",
    "        self.height = 270\n",
    "        self.frameOffset = 0\n",
    "        self.frameLength = 388800\n",
    "        self.frameSize = 129600\n",
    "        self.frameRate = 30\n",
    "        \n",
    "        \n",
    "        self.iconPathSet = iconPathSet\n",
    "        self.iconSet = [ np.array(Image.open(iconPath)) for iconPath in self.iconPathSet ]\n",
    "        ## self.iconSet = [ cv2.cvtColor(np.array(Image.open(iconPath)), cv2.COLOR_BGR2GRAY) for iconPath in self.iconPathSet ]\n",
    "        # Pre-process on brand-icons\n",
    "        self.iconInfoSet = []\n",
    "        self.orb = cv2.ORB_create() \n",
    "        for icon in self.iconSet:\n",
    "            kpi, desi = self.orb.detectAndCompute(icon,None)\n",
    "            self.iconInfoSet.append([kpi, desi])\n",
    "        \n",
    "        # Laod the .rgb video file into Memory\n",
    "        self.videoPath = videoPath\n",
    "        self.file = open(self.videoPath, 'rb')    ## consider the opne-mode!\n",
    "    \n",
    "    \n",
    "    def out_put_control(self, outPut=None, slack=5):\n",
    "        ans = []\n",
    "        i = 0\n",
    "        opNum = len(outPut)\n",
    "        while i < opNum:\n",
    "            endFrame = outPut[i][0] + slack*self.frameRate\n",
    "            k = i\n",
    "            for j in range(i, opNum):\n",
    "                if outPut[j][0] <= endFrame and outPut[j][1] == outPut[i][1]:\n",
    "                    k = j\n",
    "                else: break\n",
    "            if i == k: i += k\n",
    "            else:\n",
    "                i = k\n",
    "                ans.append( outPut[i] )\n",
    "        return ans\n",
    "    \n",
    "    \n",
    "    def img_compare(self, iconIndex, FrameIndex):\n",
    "        \n",
    "                    \n",
    "        \n",
    "    \n",
    "    def cut_copy_image(self, img, size, corner=[0,0]):\n",
    "        # initialization\n",
    "        width = 480\n",
    "        height = 270\n",
    "        cWidth = size[0]\n",
    "        cHeight = size[1]\n",
    "\n",
    "        frameSize = width*height\n",
    "        framOffsetWidth = corner[0]\n",
    "        framOffsetHeight = corner[1]\n",
    "        lineSkip = width-cWidth\n",
    "\n",
    "\n",
    "        cut = np.full((cHeight,cWidth,3), 0, np.uint8)\n",
    "\n",
    "        # cut-copy image\n",
    "        ind = framOffsetWidth + framOffsetHeight*width\n",
    "        for y in range(cHeight):\n",
    "            for x in range(cWidth):\n",
    "                cut[y][x] = [img[ind], img[ind + frameSize], img[ind + frameSize*2]]\n",
    "                ind += 1\n",
    "            ind += lineSkip\n",
    "        return cut\n",
    "    \n",
    "    \n",
    "    def detect_one_frame(self, frameNumber, iconIndex, threshHold=10, passLine=0.75, imshow=True, corner=[0,0], zoomProp=1/6):\n",
    "        isFound = False\n",
    "        \n",
    "        # initialization\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "        frameArr = np.full((pHeight, pWidth, 3), 0, np.uint8)\n",
    "        \n",
    "        # locate & laod .rgb frame\n",
    "        position = self.frameLength * frameNumber\n",
    "        self.file.seek(position, 0)\n",
    "        frameByte = self.file.read(self.frameLength)\n",
    "\n",
    "        # transfer .rgb frame to ndarray\n",
    "        frameArr = self.cut_copy_image(frameByte, [pWidth, pHeight], corner)\n",
    "        \n",
    "\n",
    "        # get key-point info of Detecting-Area\n",
    "        alignFrameArr = cv2.resize(frameArr, (480, 270), interpolation=cv2.INTER_LANCZOS4)\n",
    "        ## alignFrameArr = cv2.cvtColor(alignFrameArr, cv2.COLOR_BGR2GRAY)\n",
    "        kpf, desf = self.orb.detectAndCompute(alignFrameArr,None)\n",
    "\n",
    "        # compare with brand-icon info\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(self.iconInfoSet[iconIndex][1], desf, k=2)\n",
    "        \n",
    "        # collect good matches\n",
    "        good = []\n",
    "        imgMatchNumber = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < passLine*n.distance:\n",
    "                good.append([m])\n",
    "                if kpf[m.trainIdx].pt not in imgMatchNumber:\n",
    "                    imgMatchNumber.append(kpf[m.trainIdx].pt)\n",
    "        \n",
    "        \n",
    "        # Continue zoom-in \n",
    "        if len(good) >= threshHold:\n",
    "            isFound = True\n",
    "            if imshow:\n",
    "                print(\"  |--> Zoom-In Detection:\")\n",
    "                matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], self.iconInfoSet[iconIndex][0], alignFrameArr, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "        \n",
    "        # return result\n",
    "        if isFound:\n",
    "            print(\"        | Pass!, frame={}, icon_id={}, #good={} |\".format(frameNumber, iconIndex, len(good)))\n",
    "        else:\n",
    "            print(\"        | Not Pass!, frame={}, icon_id={}, #good={} |\".format(frameNumber, iconIndex, len(good)))\n",
    "        return isFound\n",
    "    \n",
    "    \n",
    "    def detect_zoom_in(self, img, iconIndex, threshHold=10, passLine=0.75, imshow=True, corner=[0,0], zoomProp=1/6):\n",
    "        isFound = False\n",
    "        \n",
    "        # initialization\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "\n",
    "        # regulize corner\n",
    "        corner[0] = min( int(corner[0]), int(self.width*2*zoomProp) ); corner[0] = max(corner[0], 0)\n",
    "        corner[1] = min( int(corner[1]), int(self.height*2*zoomProp) ); corner[1] = max(corner[1], 1)\n",
    "        \n",
    "        img = img[ corner[1]:corner[1]+pHeight, corner[0]:corner[0]+pWidth]\n",
    "\n",
    "        # get key-point info of Detecting-Area\n",
    "        img = cv2.resize(img, (480, 270), interpolation=cv2.INTER_LANCZOS4)\n",
    "        kpf, desf = self.orb.detectAndCompute(img,None)\n",
    "        if len(kpf)<1 or len(desf)<1:\n",
    "            return [False, [-1, -1], img]\n",
    "        \n",
    "\n",
    "        # compare with brand-icon info\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(self.iconInfoSet[iconIndex][1], desf, k=2)\n",
    "        \n",
    "        # collect good matches\n",
    "        good = []\n",
    "        imgMatchNumber = []\n",
    "        center = np.array([0, 0])\n",
    "        for m,n in matches:\n",
    "            if m.distance < passLine*n.distance:\n",
    "                good.append([m])\n",
    "                if kpf[m.trainIdx].pt not in imgMatchNumber:\n",
    "                    imgMatchNumber.append(kpf[m.trainIdx].pt)\n",
    "                center = np.array([center[0]+kpf[m.trainIdx].pt[0], center[1]+kpf[m.trainIdx].pt[1]])\n",
    "        if len(good):\n",
    "            center = center / len(good)\n",
    "        \n",
    "        # Continue zoom-in \n",
    "        if len(good) >= threshHold and len(imgMatchNumber) > 0.5*len(good): isFound = True\n",
    "\n",
    "        # return result\n",
    "        if isFound:\n",
    "            print(\"        | Pass!, icon_id={}, #good={}, len(imgMatchNumber)={} |\".format(iconIndex, len(good), len(imgMatchNumber)) )\n",
    "            if imshow:\n",
    "                print(\"    |--> Zoom-In Detection: #good =\", len(good))\n",
    "                matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], self.iconInfoSet[iconIndex][0], img, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "        else:\n",
    "            print(\"        | Not Pass!, icon_id={}, #good={}, len(imgMatchNumber) |\".format(iconIndex, len(good), len(imgMatchNumber)) )\n",
    "        return [isFound, center, img]\n",
    "    \n",
    "    \n",
    "    def detect_video_segment(self, threshHold=10, passLine=0.75, start=0, end=10, imshow=True, corner=[0,0], zoomProp=1/6, step=1):\n",
    "        begin = time.clock()\n",
    "        \n",
    "        # Initialization\n",
    "        ans = []\n",
    "        frameOffset = start*30\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "        frameArr = np.full((180,320,3), 0, np.uint8)\n",
    "        position = self.frameLength * frameOffset\n",
    "\n",
    "        # Detect brand-icons in video\n",
    "        print(\"detecting...\")\n",
    "        while frameOffset <= end*30:\n",
    "            # locate & laod .rgb frame\n",
    "            position = frameOffset * self.frameLength\n",
    "            self.file.seek(position, 0)\n",
    "            frameByte = self.file.read(self.frameLength)\n",
    "\n",
    "            # transfer .rgb frame\n",
    "            frameArr = self.cut_copy_image(frameByte, [pWidth, pHeight], corner)\n",
    "\n",
    "            # get key-point info of current-frame\n",
    "            alignFrameArr = cv2.resize(frameArr, (480, 270), interpolation=cv2.INTER_CUBIC)\n",
    "            kpf, desf = self.orb.detectAndCompute(alignFrameArr,None)\n",
    "\n",
    "            # compare with brand-icon info\n",
    "            bf = cv2.BFMatcher()\n",
    "            for iconInfo in self.iconInfoSet:\n",
    "                iconIndex = self.iconInfoSet.index(iconInfo)\n",
    "                matches = bf.knnMatch(iconInfo[1],desf, k=2)  ## what is 'k'?\n",
    "                # collect good matches & calculate gravity-center\n",
    "                good = []\n",
    "                center = np.array([0, 0])\n",
    "                for m,n in matches:\n",
    "                    if m.distance < passLine*n.distance:\n",
    "                        good.append([m])\n",
    "                        center = np.array([center[0]+kpf[m.trainIdx].pt[0], center[1]+kpf[m.trainIdx].pt[1]])\n",
    "                if len(good):\n",
    "                    center = center / len(good)\n",
    "                \n",
    "                ## Continue Zoom-In:\n",
    "                prop = 1/5\n",
    "                zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                if len(good) >= threshHold:\n",
    "                    print(\"B\")\n",
    "                    isFound, center, img = self.detect_zoom_in(alignFrameArr, iconIndex, threshHold=8, corner=zoomCorner, zoomProp=1/5)\n",
    "                    if isFound:\n",
    "                        print(\"C\"); \n",
    "                        zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                        isFound, center, img = self.detect_zoom_in(img, iconIndex, threshHold=8, corner=zoomCorner, zoomProp=1/5)\n",
    "                    if isFound:\n",
    "                        ans.append( [iconIndex, frameOffset] )\n",
    "                        if imshow:\n",
    "                            print(\"Alternative-Frame: \\nframeOffset =\", frameOffset, \"time =\", int(frameOffset/30), \"  icon_ind =\", iconIndex, \"  #good =\", len(good))\n",
    "                            matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], iconInfo[0], alignFrameArr, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                            print(\"A\"); plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "            frameOffset += step\n",
    "\n",
    "        # Return\n",
    "        print(\"Detection finished in {} seconds.\".format(time.clock()-begin))\n",
    "        return ans\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "detect_1 = DetectIcon(videoPath=r'./data/data_test1.rgb', iconPathSet=[r'./data/subway_logo.jpg', r'./data/starbucks_logo.jpg'])\n",
    "## detect_1.detect_one_frame(2818, 0, threshHold=1, corner=[0, 70], zoomProp=10/30)\n",
    "## detect_1.detect_one_frame(2822, 0, threshHold=1, corner=[0, 70], zoomProp=10/30)\n",
    "## detect_1.detect_one_frame(448, 0, threshHold=1, corner=[0, 40], zoomProp=11/30)\n",
    "ans_1 = detect_1.detect_video_segment(threshHold=10, start=70, end=71, step=2); print(len(ans_1), ans_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
